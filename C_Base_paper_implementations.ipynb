{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c16acd7213b54fabb1fea55612e283ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91855548c7f74eb9980a2f5157c0b1ff",
              "IPY_MODEL_3502e05ea5a9492c943ea2a89b2e8913",
              "IPY_MODEL_b2f00c5505224ff18409a5c7ae27c02f"
            ],
            "layout": "IPY_MODEL_c36ea444d679459299d2b0e8680a01e5"
          }
        },
        "91855548c7f74eb9980a2f5157c0b1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86173e522d2f4f14a833fe42a1cbe309",
            "placeholder": "​",
            "style": "IPY_MODEL_4a3bd02f1a054f72b171009d77076bf0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3502e05ea5a9492c943ea2a89b2e8913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33eff0b93fab439a8555b7916d7242e7",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da12dfd22f02480f966f6577fa98c629",
            "value": 48
          }
        },
        "b2f00c5505224ff18409a5c7ae27c02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ddc83f25de143ad8f084b5e4f8938b8",
            "placeholder": "​",
            "style": "IPY_MODEL_1c8bbee2569c48198715e85f43029a97",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.08kB/s]"
          }
        },
        "c36ea444d679459299d2b0e8680a01e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86173e522d2f4f14a833fe42a1cbe309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a3bd02f1a054f72b171009d77076bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33eff0b93fab439a8555b7916d7242e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da12dfd22f02480f966f6577fa98c629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ddc83f25de143ad8f084b5e4f8938b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c8bbee2569c48198715e85f43029a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b50d8e1d919144e18e2fc88e0d314e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29fb0cb0832149878bda5a1fd95e0af4",
              "IPY_MODEL_8b33fee5183348469c804e5083fd1505",
              "IPY_MODEL_f07b56ae279b42cfb39b8b452943f4f5"
            ],
            "layout": "IPY_MODEL_b42fe3cff24c4c00a75beeb348a15c23"
          }
        },
        "29fb0cb0832149878bda5a1fd95e0af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05966bbe8d5c417e8934f4bd229f85f6",
            "placeholder": "​",
            "style": "IPY_MODEL_a2a4d8da92a542f5baba3dcff9ff50fd",
            "value": "vocab.txt: 100%"
          }
        },
        "8b33fee5183348469c804e5083fd1505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0338f79bc50d484690107fae2f7c4402",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_676983bed9f046c7a5453a8985a6305e",
            "value": 231508
          }
        },
        "f07b56ae279b42cfb39b8b452943f4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9756bc8f0ef4f7cbe6b06371a1f7748",
            "placeholder": "​",
            "style": "IPY_MODEL_1c4703f1729c4e1f889c800d0f5c3541",
            "value": " 232k/232k [00:00&lt;00:00, 1.02MB/s]"
          }
        },
        "b42fe3cff24c4c00a75beeb348a15c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05966bbe8d5c417e8934f4bd229f85f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a4d8da92a542f5baba3dcff9ff50fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0338f79bc50d484690107fae2f7c4402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "676983bed9f046c7a5453a8985a6305e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9756bc8f0ef4f7cbe6b06371a1f7748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c4703f1729c4e1f889c800d0f5c3541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5779a3b3c9f84e9492e7785b045414b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f80b9c42f4fa432189a4a4f81775a6d7",
              "IPY_MODEL_570fe088d9d84d6b9ad1d214a74d5d56",
              "IPY_MODEL_6365136104864aeeb6e9987ecfdd13b7"
            ],
            "layout": "IPY_MODEL_f373352b0e25486d856bbfff6f48a01a"
          }
        },
        "f80b9c42f4fa432189a4a4f81775a6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91c2d94f60db493590251c31cfa6a8ab",
            "placeholder": "​",
            "style": "IPY_MODEL_ad17906a21904ccbaf9510b1a582084c",
            "value": "tokenizer.json: 100%"
          }
        },
        "570fe088d9d84d6b9ad1d214a74d5d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c509dd23d18a4a5dad6041c21d294bc1",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5e6c951c43c4c0686b45b095725c2a4",
            "value": 466062
          }
        },
        "6365136104864aeeb6e9987ecfdd13b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1174ccdf9c44c1836bc4f614ab8303",
            "placeholder": "​",
            "style": "IPY_MODEL_dc74fcd24ba147d4a6f24ce04e76b782",
            "value": " 466k/466k [00:00&lt;00:00, 656kB/s]"
          }
        },
        "f373352b0e25486d856bbfff6f48a01a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c2d94f60db493590251c31cfa6a8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad17906a21904ccbaf9510b1a582084c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c509dd23d18a4a5dad6041c21d294bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e6c951c43c4c0686b45b095725c2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f1174ccdf9c44c1836bc4f614ab8303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc74fcd24ba147d4a6f24ce04e76b782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72906eeea1a146a8b7f7e0a674ddb6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ddcaca153814a3f9d9d976e1cfdb8bb",
              "IPY_MODEL_5642c9e0caed455aa447af4caccf8851",
              "IPY_MODEL_7b9fb2ebea8b4c90b6123188808867b0"
            ],
            "layout": "IPY_MODEL_744782b8ec4a47259cb84b6cafcff28a"
          }
        },
        "1ddcaca153814a3f9d9d976e1cfdb8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb467ba2328e42cdb4f2724242adce7d",
            "placeholder": "​",
            "style": "IPY_MODEL_397a665d708e44f8916cce78578f07b1",
            "value": "config.json: 100%"
          }
        },
        "5642c9e0caed455aa447af4caccf8851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f632dd33bbbe45a89460e9cbbe0766e3",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_728bfb5b0ba242faad8803b8d8853c35",
            "value": 570
          }
        },
        "7b9fb2ebea8b4c90b6123188808867b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9049e44052495ab650178f9d36389e",
            "placeholder": "​",
            "style": "IPY_MODEL_06cbd01e16c348d1afbb351815e03ecd",
            "value": " 570/570 [00:00&lt;00:00, 29.0kB/s]"
          }
        },
        "744782b8ec4a47259cb84b6cafcff28a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb467ba2328e42cdb4f2724242adce7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397a665d708e44f8916cce78578f07b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f632dd33bbbe45a89460e9cbbe0766e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728bfb5b0ba242faad8803b8d8853c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de9049e44052495ab650178f9d36389e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06cbd01e16c348d1afbb351815e03ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1c82d384fd447999a8ca75bfe7a61d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68aeed6a9654445a8af7f98de39221e5",
              "IPY_MODEL_7814215843554b5da02ba82df048eae0",
              "IPY_MODEL_dfe22309ab0141228aaccbf30759d825"
            ],
            "layout": "IPY_MODEL_2bb6ec62f1b14bfb8be816b75af18ac9"
          }
        },
        "68aeed6a9654445a8af7f98de39221e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_617cc9dd5f14469692d3b9d71debfc50",
            "placeholder": "​",
            "style": "IPY_MODEL_6b1f6991f6be46aeade30de0f2bf56b5",
            "value": "model.safetensors: 100%"
          }
        },
        "7814215843554b5da02ba82df048eae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c20fdde698f24658982ac5c1841e3812",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2973dbad5e564e838023f5ca52279de9",
            "value": 440449768
          }
        },
        "dfe22309ab0141228aaccbf30759d825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cf196ad3fa648c9ae77b622e2278eac",
            "placeholder": "​",
            "style": "IPY_MODEL_bcf498359c1b459f95c278bdc34115dc",
            "value": " 440M/440M [00:01&lt;00:00, 242MB/s]"
          }
        },
        "2bb6ec62f1b14bfb8be816b75af18ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "617cc9dd5f14469692d3b9d71debfc50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1f6991f6be46aeade30de0f2bf56b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c20fdde698f24658982ac5c1841e3812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2973dbad5e564e838023f5ca52279de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cf196ad3fa648c9ae77b622e2278eac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf498359c1b459f95c278bdc34115dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Public Requirement Dataset\n",
        "In this research, authors used PURE dataset which contains 79 requirements documents in different forms. It is publicly available on the internet for research use. In this dataset requirements documents had written in natural English language. And it can be used for NLP tasks such as ambiguity detection, identification and requirements categorisation"
      ],
      "metadata": {
        "id": "EwZJEkQxPKiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "COlUVZeCM2Vv",
        "outputId": "38bd83fc-0793-46b2-ac66-dc577bb154a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0fb19594-f73b-44c8-bad3-5669882ada02\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0fb19594-f73b-44c8-bad3-5669882ada02\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Pure_Annotate_Dataset.csv to Pure_Annotate_Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset_path = 'Pure_Annotate_Dataset.csv'\n",
        "try:\n",
        "    df = pd.read_csv(dataset_path, encoding='ISO-8859-1')\n",
        "except UnicodeDecodeError:\n",
        "    # If ISO-8859-1 doesn't work, you can try 'latin1' or 'utf-16'\n",
        "    df = pd.read_csv(dataset_path, encoding='latin1')\n",
        "\n",
        "# Display a success message and preview the dataset\n",
        "print(\"Dataset Loaded Successfully\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Information:\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj4SI-4oOCCS",
        "outputId": "b3d298a7-ad15-47a8-90fa-38967b960ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded Successfully\n",
            "                                                  id  \\\n",
            "0  CCHIT Certified 2011 Ambulatory EHR Criteria 2...   \n",
            "1  CCHIT Certified 2011 Ambulatory EHR Criteria 2...   \n",
            "2  CCHIT Certified 2011 Ambulatory EHR Criteria 2...   \n",
            "3  CCHIT Certified 2011 Ambulatory EHR Criteria 2...   \n",
            "4  CCHIT Certified 2011 Ambulatory EHR Criteria 2...   \n",
            "\n",
            "                                            sentence  security  reliability  \\\n",
            "0  The system shall create a single patient recor...         0            0   \n",
            "1  The system shall associate (store and link) ke...         0            0   \n",
            "2  The system shall provide the ability to store ...         0            0   \n",
            "3  The system shall provide a field which will id...         0            0   \n",
            "4  The system shall provide the ability to merge ...         0            0   \n",
            "\n",
            "   NFR_boolean  \n",
            "0            0  \n",
            "1            0  \n",
            "2            0  \n",
            "3            0  \n",
            "4            0  \n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11440 entries, 0 to 11439\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   id           11440 non-null  object\n",
            " 1   sentence     11440 non-null  object\n",
            " 2   security     11440 non-null  int64 \n",
            " 3   reliability  11440 non-null  int64 \n",
            " 4   NFR_boolean  11440 non-null  int64 \n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 447.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-processing\n",
        "After uploading the dataset successfully, we will have to preprocess the dataset because some sentences or paragraphs in these documents are irrelevant to the requirements and need to be excluded from requirement sentences. For this purpose, we performed this task in three steps: **tokenization**, **data cleaning**, and **normalization**."
      ],
      "metadata": {
        "id": "2dc7fKoyQkLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# Download necessary resources for nltk (only needed once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRM7WOxEPEmn",
        "outputId": "b99366f4-ee19-4929-eac6-f2549315cf73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During Tokenization, requirements document is broken up into smaller segments.This process is also called data preparation. The requirements document in this process is broken into paragraphs, and the paragraph into sentences. In our experiments, we used **sentence tokenization function nltk, which is a python library** used to extract English sentences from a document"
      ],
      "metadata": {
        "id": "8SF2pmQZTIVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt') # Download the required tokenizer\n",
        "\n",
        "# Tokenize each sentence in the 'sentence' column and add new column 'tokens'\n",
        "df['tokens'] = df['sentence'].apply(word_tokenize)\n",
        "\n",
        "# Display the original text and its tokenized version\n",
        "print(df[['sentence', 'tokens']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5E3WfytR1QP",
        "outputId": "03ac69a1-9b24-4097-d200-8d33b47d8dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            sentence  \\\n",
            "0  The system shall create a single patient recor...   \n",
            "1  The system shall associate (store and link) ke...   \n",
            "2  The system shall provide the ability to store ...   \n",
            "3  The system shall provide a field which will id...   \n",
            "4  The system shall provide the ability to merge ...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [The, system, shall, create, a, single, patien...  \n",
            "1  [The, system, shall, associate, (, store, and,...  \n",
            "2  [The, system, shall, provide, the, ability, to...  \n",
            "3  [The, system, shall, provide, a, field, which,...  \n",
            "4  [The, system, shall, provide, the, ability, to...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of data cleaning process is to clean all irrelevant tokens from requirement sentences. This task is based on three steps.\n",
        "1.   Punctuation removal, occur in this step such as full stops, question marks, commas,colons, etc are removed from the requirement sentences.\n",
        "2.   The second step is stop-word removal like high frequency words, such as (’they’, ’them’, ’their’, you,should, from etc) that don’t add any essential information to the requirement sentence.\n",
        "3. The last step of data cleaning task is Non-alphabetic tokens removal\n",
        "that didn’t contain useful information\n",
        "\n",
        "In our model, **we used python library called Natural Language Tool Kit (NLTK)**.This library con\u0002tains most of the stop words in English language."
      ],
      "metadata": {
        "id": "nTsyXwKfVOOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a function to clean each token in the tokenized list\n",
        "def clean_tokens(tokens):\n",
        "    # Remove special characters and numbers, and convert each token to lowercase\n",
        "    cleaned_tokens = [re.sub(r'[^A-Za-z]', '', token).lower()\n",
        "    for token in tokens if re.sub(r'[^A-Za-z]', '', token)]\n",
        "    return cleaned_tokens\n",
        "\n",
        "# Apply data cleaning to each list of tokens in the 'tokens' column\n",
        "df['cleaned_tokens'] = df['tokens'].apply(clean_tokens)\n",
        "\n",
        "print(df[['tokens', 'cleaned_tokens']].head()) # Display the original tokens and cleaned tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leDSvEuSUAsb",
        "outputId": "ce53acf4-6de9-452f-b4ca-ca9aae00e07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              tokens  \\\n",
            "0  [The, system, shall, create, a, single, patien...   \n",
            "1  [The, system, shall, associate, (, store, and,...   \n",
            "2  [The, system, shall, provide, the, ability, to...   \n",
            "3  [The, system, shall, provide, a, field, which,...   \n",
            "4  [The, system, shall, provide, the, ability, to...   \n",
            "\n",
            "                                      cleaned_tokens  \n",
            "0  [the, system, shall, create, a, single, patien...  \n",
            "1  [the, system, shall, associate, store, and, li...  \n",
            "2  [the, system, shall, provide, the, ability, to...  \n",
            "3  [the, system, shall, provide, a, field, which,...  \n",
            "4  [the, system, shall, provide, the, ability, to...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In normalization process, **we aimed to convert all the words to a more uniform sequence** by transform it to a common base form. For normalization, we’ll use lemmatization to convert each word to its base (root) form. **Lemmatization** is preferred over stemming because it produces actual words (e.g., \"running\" becomes \"run\" instead of \"runn\"). In this task, we improve the text modelling and matching."
      ],
      "metadata": {
        "id": "D46sI78MWwtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') # Download WordNet data for lemmatization\n",
        "\n",
        "lemmatizer = WordNetLemmatizer() # Initialize the lemmatizer\n",
        "\n",
        "# Define a function\n",
        "def lemmatize_tokens(tokens):\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return lemmatized_tokens #lemmatize each token in the cleaned tokens list\n",
        "\n",
        "# Create the new column 'lemmatized_toekn' Apply lemmatization to each list of cleaned tokens\n",
        "df['lemmatized_tokens'] = df['cleaned_tokens'].apply(lemmatize_tokens)\n",
        "\n",
        "# Display the original, cleaned, and lemmatized tokens\n",
        "print(df[['tokens', 'cleaned_tokens', 'lemmatized_tokens']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTDEA81iW4XT",
        "outputId": "e63f7268-bbff-457b-e39c-2344e8e04168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              tokens  \\\n",
            "0  [The, system, shall, create, a, single, patien...   \n",
            "1  [The, system, shall, associate, (, store, and,...   \n",
            "2  [The, system, shall, provide, the, ability, to...   \n",
            "3  [The, system, shall, provide, a, field, which,...   \n",
            "4  [The, system, shall, provide, the, ability, to...   \n",
            "\n",
            "                                      cleaned_tokens  \\\n",
            "0  [the, system, shall, create, a, single, patien...   \n",
            "1  [the, system, shall, associate, store, and, li...   \n",
            "2  [the, system, shall, provide, the, ability, to...   \n",
            "3  [the, system, shall, provide, a, field, which,...   \n",
            "4  [the, system, shall, provide, the, ability, to...   \n",
            "\n",
            "                                   lemmatized_tokens  \n",
            "0  [the, system, shall, create, a, single, patien...  \n",
            "1  [the, system, shall, associate, store, and, li...  \n",
            "2  [the, system, shall, provide, the, ability, to...  \n",
            "3  [the, system, shall, provide, a, field, which,...  \n",
            "4  [the, system, shall, provide, the, ability, to...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction (Vectorization)\n",
        "After Data pre-processing, the second step in our methodology is to extract representative features from the requirement sentences using a various number of features extraction techniques used in the NLP.\n",
        "\n",
        "In research, authors used four vectorization techniques in NLP. Two of them are **syntactical based methods: TF and TF-IDF**. The other two vectorizatin methods are **semantically based methods: Word2Vec4 and BERT5.**"
      ],
      "metadata": {
        "id": "5eWLHfSFYlCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Term Frequency\n",
        "**Term Frequency** is one of the basic vectorization methods and information retrieval in NLP. In our approach, we use this method to count how many\n",
        "times each word in the requirement sentences appears in all\n",
        "requirement documents and represent it as a vector.\n",
        "\n",
        "We created words dictionary containing all normalized words in the requirement document. This process also called **bag of words (BOW)**. The rows corresponds to a requirement sentence and each column represents a unique word. The occurrence number in case the word is exist in the sentence increasing by one."
      ],
      "metadata": {
        "id": "SdIGGl9KZY6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert preprocessed text into a format suitable for vectorization\n",
        "preprocessed_text = df['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Initialize CountVectorizer to compute TF\n",
        "tf_vectorizer = CountVectorizer()\n",
        "tf_matrix = tf_vectorizer.fit_transform(preprocessed_text)\n",
        "\n",
        "# Display TF feature matrix\n",
        "print(\"TF Matrix Shape:\", tf_matrix.shape)\n",
        "print(\"Sample TF Matrix:\", tf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S1lprZVZAm2",
        "outputId": "ac69baab-16aa-4941-8750-7f153dc836c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Matrix Shape: (11440, 6153)\n",
            "Sample TF Matrix: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Checking the shape of tf_matrix to determine the number of rows\n",
        "num_rows = tf_matrix.shape[0]\n",
        "\n",
        "row_index = 0  # Use 0 to access the first row\n",
        "if row_index < num_rows:\n",
        "    second_array = tf_matrix[row_index].toarray()[0]\n",
        "\n",
        "    limited_array = second_array[:15] # Limit the array to 15 indexes\n",
        "\n",
        "    print(\"Second array (limited to 15 elements):\", limited_array)\n",
        "else:\n",
        "    print(f\"Error: Row index {row_index} is out of range. tf_matrix has {num_rows} rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbmrAiXtvgju",
        "outputId": "c1b34a67-72b8-4367-d2de-c21293a2075b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second array (limited to 15 elements): [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this technique of **TF-IDF (Term Frequency Inverse Document Frequency)**, we quantify a word in requirement documents. Weight of each word were computed which signifies of its importance in all requirement documents. This method is widely used in information retrieval in NLP. This methods will improve the basic features that can be extracted from the requirement sentences so that can differentiate between NFR categories."
      ],
      "metadata": {
        "id": "uErJ-uHjbM-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TfidfVectorizer to compute TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_text)\n",
        "\n",
        "# Display TF-IDF feature matrix\n",
        "print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
        "print(\"Sample TF-IDF Matrix:\", tfidf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UIhHvJfbjZn",
        "outputId": "da01db76-0f8f-43ca-b5a4-50bedced4d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix Shape: (11440, 6153)\n",
            "Sample TF-IDF Matrix: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2vec** is a common word embedding model provided by Google to improve words representation. In our research, Word2Vec is used to enhance the numeric representation of the words through increase the accuracy of capturing word context from a document in semantic and syntactic words relationship. The value of each feature in the word representation ranging from zero to one.\n",
        "\n",
        "The objective of using this model in this study is to invest the affect of semantic representation for requirement sentences using big data model to achieve high accuracy in NFR classification."
      ],
      "metadata": {
        "id": "Bb0gKq8WcyMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Train Word2Vec model on the tokenized data\n",
        "word2vec_model = Word2Vec(sentences=df['lemmatized_tokens'],\n",
        "                          vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# To get the vector for a word, e.g., 'requirement'\n",
        "print(\"Vector for 'requirement':\", word2vec_model.wv['requirement'])\n",
        "\n",
        "# Aggregate vectors to represent each document\n",
        "df['word2vec_vectors'] = df['lemmatized_tokens'].apply(lambda tokens:\n",
        "                                                       sum(word2vec_model.wv[token]\n",
        "                                                                          for token in tokens\n",
        "                                                           if token in word2vec_model.wv))"
      ],
      "metadata": {
        "id": "LSi3AulGca7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f6fc77-edcc-470b-929e-e3d2d342587b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'requirement': [-0.2656624   0.24085735  0.17579813  1.1480407   0.07920082 -0.9877641\n",
            "  0.8354378   0.98058563 -0.59377414 -0.8023467  -0.4324077  -1.4503976\n",
            "  0.5959428   0.52127653  0.00417846  0.4226356   0.14965805 -0.3720479\n",
            " -0.37842363 -0.7833258   0.7568334   0.5718663   0.29422912  0.1621622\n",
            "  0.12471768 -0.08909896 -0.30672985 -0.37583214 -0.3022516  -0.10667772\n",
            "  0.4749707  -0.11869216 -0.03090043 -0.8112786  -0.374059    0.98669297\n",
            "  0.6877831  -0.6082959   0.1219599  -0.7228267   0.42638066 -0.36590284\n",
            " -0.52137285  0.02665865  0.5976789   0.33254704 -0.23943973 -0.31975004\n",
            "  0.46090502  0.23530722  0.43688154 -0.24952984 -0.44665536 -0.20535974\n",
            " -0.8534624   0.38300374  0.0474469  -0.48625425 -0.82194155 -0.40102872\n",
            " -0.05814507  0.3400637  -0.17363532  0.24904467 -0.49357018 -0.06357519\n",
            " -0.537737    0.6812649  -0.36957672  0.43888995 -0.43545935  0.15301293\n",
            "  0.7603106  -0.0136522   0.60375935  0.43822363 -0.19659933 -0.07213023\n",
            "  0.02409289  0.45327142 -0.56875914 -0.30881295 -0.48444366  0.77014536\n",
            " -0.3074531   0.13193782  1.0017924   1.0614419   0.1154169  -0.4980323\n",
            "  0.26164088  0.52102256  0.09663207 -0.02696397  0.7878849   0.24152431\n",
            " -0.5470938  -0.62406063  0.58796865  0.36134115]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT** is a text representation technique stands for **Bi-directional Encoder Representations from Transformers**. BERT is an inflection point in the application of machine learning for NLP and confirmed to be state-of-the-art for a wide range of NLP tasks such semantic analysis and text classification. In this research paper, authors used BERT model with Masked-LM strategy to represent requirement sentences in semantic numerical vectors. Then, they trained the classifiers on top of the transformer output of the BERT model."
      ],
      "metadata": {
        "id": "MT3JfpaleBQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "# import pandas as pd\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Move model to GPU if available, else stay on CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to extract BERT embeddings for each sentence\n",
        "def get_bert_embeddings(text):\n",
        "    # Tokenize the sentence with padding and truncation (handles varying sentence lengths)\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move to the correct device (GPU or CPU)\n",
        "\n",
        "    # Get the model outputs (outputs[0] is the last hidden state)\n",
        "    with torch.no_grad():  # Disable gradient calculation as we're not training\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # We use the [CLS] token (first token in BERT) as the sentence embedding\n",
        "    sentence_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # Move back to CPU and convert to numpy\n",
        "    return sentence_embedding\n",
        "\n",
        "# Apply BERT embeddings to each sentence and Use 'lemmatized_tokens\n",
        "df['bert_embeddings'] = df['lemmatized_tokens'].apply(lambda x: get_bert_embeddings(' '.join(x)))\n",
        "\n",
        "# Check the shape of the resulting embeddings\n",
        "print(f\"BERT Embeddings Shape: {df['bert_embeddings'].iloc[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "c16acd7213b54fabb1fea55612e283ab",
            "91855548c7f74eb9980a2f5157c0b1ff",
            "3502e05ea5a9492c943ea2a89b2e8913",
            "b2f00c5505224ff18409a5c7ae27c02f",
            "c36ea444d679459299d2b0e8680a01e5",
            "86173e522d2f4f14a833fe42a1cbe309",
            "4a3bd02f1a054f72b171009d77076bf0",
            "33eff0b93fab439a8555b7916d7242e7",
            "da12dfd22f02480f966f6577fa98c629",
            "2ddc83f25de143ad8f084b5e4f8938b8",
            "1c8bbee2569c48198715e85f43029a97",
            "b50d8e1d919144e18e2fc88e0d314e91",
            "29fb0cb0832149878bda5a1fd95e0af4",
            "8b33fee5183348469c804e5083fd1505",
            "f07b56ae279b42cfb39b8b452943f4f5",
            "b42fe3cff24c4c00a75beeb348a15c23",
            "05966bbe8d5c417e8934f4bd229f85f6",
            "a2a4d8da92a542f5baba3dcff9ff50fd",
            "0338f79bc50d484690107fae2f7c4402",
            "676983bed9f046c7a5453a8985a6305e",
            "c9756bc8f0ef4f7cbe6b06371a1f7748",
            "1c4703f1729c4e1f889c800d0f5c3541",
            "5779a3b3c9f84e9492e7785b045414b8",
            "f80b9c42f4fa432189a4a4f81775a6d7",
            "570fe088d9d84d6b9ad1d214a74d5d56",
            "6365136104864aeeb6e9987ecfdd13b7",
            "f373352b0e25486d856bbfff6f48a01a",
            "91c2d94f60db493590251c31cfa6a8ab",
            "ad17906a21904ccbaf9510b1a582084c",
            "c509dd23d18a4a5dad6041c21d294bc1",
            "b5e6c951c43c4c0686b45b095725c2a4",
            "8f1174ccdf9c44c1836bc4f614ab8303",
            "dc74fcd24ba147d4a6f24ce04e76b782",
            "72906eeea1a146a8b7f7e0a674ddb6ec",
            "1ddcaca153814a3f9d9d976e1cfdb8bb",
            "5642c9e0caed455aa447af4caccf8851",
            "7b9fb2ebea8b4c90b6123188808867b0",
            "744782b8ec4a47259cb84b6cafcff28a",
            "eb467ba2328e42cdb4f2724242adce7d",
            "397a665d708e44f8916cce78578f07b1",
            "f632dd33bbbe45a89460e9cbbe0766e3",
            "728bfb5b0ba242faad8803b8d8853c35",
            "de9049e44052495ab650178f9d36389e",
            "06cbd01e16c348d1afbb351815e03ecd",
            "c1c82d384fd447999a8ca75bfe7a61d4",
            "68aeed6a9654445a8af7f98de39221e5",
            "7814215843554b5da02ba82df048eae0",
            "dfe22309ab0141228aaccbf30759d825",
            "2bb6ec62f1b14bfb8be816b75af18ac9",
            "617cc9dd5f14469692d3b9d71debfc50",
            "6b1f6991f6be46aeade30de0f2bf56b5",
            "c20fdde698f24658982ac5c1841e3812",
            "2973dbad5e564e838023f5ca52279de9",
            "4cf196ad3fa648c9ae77b622e2278eac",
            "bcf498359c1b459f95c278bdc34115dc"
          ]
        },
        "id": "yiYr2hz4eA9j",
        "outputId": "75ba9665-c041-4698-f4d8-b35fbd10645d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c16acd7213b54fabb1fea55612e283ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b50d8e1d919144e18e2fc88e0d314e91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5779a3b3c9f84e9492e7785b045414b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72906eeea1a146a8b7f7e0a674ddb6ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1c82d384fd447999a8ca75bfe7a61d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Embeddings Shape: (1, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the Data into Training and Testing Sets\n",
        "Before applying machine learning models, we need to split the data into a training set and a test set. We will also convert the BERT embeddings into a format that can be used by these models."
      ],
      "metadata": {
        "id": "qyXc73_qoBSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'bert_embeddings' is the column containing your BERT embeddings and 'NFR_boolean' contains the target labels\n",
        "X = df['bert_embeddings'].apply(lambda x: x.flatten())  # Flatten the BERT embeddings\n",
        "y = df['NFR_boolean']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"BERT Embeddings and labels extracted successfully.\")\n",
        "\n",
        "# Get the lengths of the training and testing sets\n",
        "train_size = len(X_train)\n",
        "test_size = len(X_test)\n",
        "\n",
        "# Calculate the ratio\n",
        "total_size = train_size + test_size\n",
        "train_ratio = train_size / total_size\n",
        "test_ratio = test_size / total_size\n",
        "\n",
        "# Print the results\n",
        "print(f\"Training set size: {train_size}\")\n",
        "print(f\"Testing set size: {test_size}\")\n",
        "print(f\"Total dataset size: {total_size}\")\n",
        "print(f\"Training set ratio: {train_ratio:.2f}\")\n",
        "print(f\"Testing set ratio: {test_ratio:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3c4ofksoS-x",
        "outputId": "cdae1b8f-32da-4445-a80a-8fc07334ad88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Embeddings and labels extracted successfully.\n",
            "Training set size: 9152\n",
            "Testing set size: 2288\n",
            "Total dataset size: 11440\n",
            "Training set ratio: 0.80\n",
            "Testing set ratio: 0.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evSpf-8DtP_I",
        "outputId": "549db0be-daec-4ea3-8386-82027d40d6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8746     [-0.29028362, -0.0069290344, -0.58969885, 0.00...\n",
            "11395    [-0.39160356, -0.089262, 0.41657862, 0.1582935...\n",
            "36       [-0.5227131, -0.03067437, -0.020269044, -0.062...\n",
            "11257    [-0.2579271, -0.051638927, 0.09467344, 0.05525...\n",
            "3334     [-0.4160419, -0.5469826, 0.44621208, -0.131847...\n",
            "                               ...                        \n",
            "11284    [-0.1615796, -0.07516419, 0.15448351, 0.119395...\n",
            "5191     [-0.4032112, -0.04167419, -0.15463793, -0.2913...\n",
            "5390     [0.05034938, 0.28090125, -0.5540273, 0.226953,...\n",
            "860      [-0.55429906, 0.07363611, 0.11128484, -0.26137...\n",
            "7270     [-0.20526685, -0.073073134, -0.1182015, 0.1541...\n",
            "Name: bert_embeddings, Length: 9152, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiDm4ECTtdFs",
        "outputId": "ac7b6eac-d128-4a35-847b-b77eec738e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11013    [-0.3247295, 0.1726643, 0.22044359, 0.10864598...\n",
            "6123     [-0.23559381, 0.35876867, -0.10723287, -0.5350...\n",
            "10633    [-0.22872213, 0.17400908, -0.03794982, 0.21764...\n",
            "2270     [-0.16080384, 0.05171148, -0.04882351, 0.04860...\n",
            "5271     [-0.09217936, -0.5087056, -0.36632246, -0.0474...\n",
            "                               ...                        \n",
            "5773     [-0.13863471, 0.208345, -0.71376586, -0.362303...\n",
            "6657     [-0.011860309, 0.15282507, -0.061276775, 0.064...\n",
            "4220     [-0.20356126, 0.3949012, -0.18463196, -0.24909...\n",
            "1224     [-0.12972067, 0.11177402, 0.0034937877, -0.071...\n",
            "7698     [-0.122205585, -0.16259454, 0.3718352, -0.1792...\n",
            "Name: bert_embeddings, Length: 2288, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Classifier\n",
        "In previous stages of proposed system, Authors segmented requirements documents into sentences, then each sentence were converted into a numerical representation in the form of a vector in order to be used by ML models. In this Phase, Authors built ML models to classify the vectors that represent requirements sentences into our target **NFR categories (classes)** **usability**, **availability**, **reliability**, **security**, **performance or** **others**. We choose the most common three supervised ML algorithms applied to a similar task: **Naive Bayse**, **Support Vector Machine**, and **Logistic Regression**."
      ],
      "metadata": {
        "id": "CQHJbzZIiTnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **Support Vector Machine (SVM)** is a powerful machine learning algorithm widely used for both linear and nonlinear classification, as well as regression and outlier detection tasks. SVMs are highly adaptable, making them suitable for various applications such as text classification, image classification, spam detection, handwriting identification, gene expression analysis, face detection, and anomaly detection.\n",
        "\n",
        "SVM is a discriminative classification method which is commonly recognized to be more accurate in NLP. Inthis research, SVM classifier were used to solve non-linear classification problem using a “kernel trick\", which is a method for using a linear classification model to solve a non linear problem by projecting the feature vectors of the target classes into a higher dimension in which the classes are linearly separable.\n",
        "\n",
        "In research, authors have five classes of NFR and the others class. The traditional SVM classifier is a binary classifier that can be applied to two classes only. In this case, authors have multiple classes (i.e. six classes). To handle this issue one-against-one and one-against-all strategies are\n",
        "used. In order to maximize the margin of the hyperplane, the weight of each feature is minimized using gradient descent algorithm with cost function algorithm."
      ],
      "metadata": {
        "id": "JTaTs0iTkNlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)  # You can experiment with different kernels and C values\n",
        "\n",
        "# Train the SVM classifier and convert X-train to list\n",
        "svm_classifier.fit(X_train.to_list(), y_train)\n",
        "\n",
        "# Make predictions on the test set and convert X-test to a list\n",
        "y_pred = svm_classifier.predict(X_test.to_list())\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of SVM classifier: {accuracy}\")\n",
        "\n",
        "# Generate and print a classification report with precision, recall, and F1 score\n",
        "svm_report = classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1'])\n",
        "print(\"SVM Classification Report:\\n\", svm_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcLEmzUZscNp",
        "outputId": "f1872587-1c33-4c97-9571-33815fd16c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of SVM classifier: 0.9042832167832168\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.93      0.95      0.94      1931\n",
            "     Class 1       0.72      0.63      0.67       357\n",
            "\n",
            "    accuracy                           0.90      2288\n",
            "   macro avg       0.83      0.79      0.81      2288\n",
            "weighted avg       0.90      0.90      0.90      2288\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayse classifier** is another classifier we adopted in our methodology. This classifier is a probabilistic model based on Bayes theorem. A number of properties in this classifier have prompted us to use it in our NFR classification model. Naive Bayes is one of the most common used supervised ML classifiers.\n",
        "\n",
        "NB is demonstrated to be accurate and reliable in natural language classification tasks. NB classifier does not require a lot of training data which is one of the issues that led us to choose it in our research."
      ],
      "metadata": {
        "id": "hydYWXLTzOwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train the Naive Bayes classifier.  MultinomialNB expects non-negative values.\n",
        "nb_classifier = MultinomialNB() # Initialize the Naive Bayes classifier\n",
        "\n",
        "# Option 1: Since BERT embeddings can be negative, we'll need to handle this:\n",
        "X_train_clipped = X_train.apply(lambda x: np.clip(x, 0, None))\n",
        "nb_classifier.fit(X_train_clipped.to_list(), y_train)\n",
        "\n",
        "# Option 2:  Scale data to be positive.\n",
        "# scaler = MinMaxScaler()\n",
        "# X_train_scaled = scaler.fit_transform(np.vstack(X_train.values))\n",
        "# X_test_scaled = scaler.transform(np.vstack(X_test.values))\n",
        "# nb_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set (remember to handle negative values)\n",
        "X_test_clipped = X_test.apply(lambda x: np.clip(x, 0, None))\n",
        "y_pred = nb_classifier.predict(X_test_clipped.to_list())\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred) # Evaluate the model\n",
        "print(f\"Accuracy of Naive Bayes classifier: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5DoEOb-wRz_",
        "outputId": "74d047fc-9472-4aa9-f4e7-683a48b9c6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Naive Bayes classifier: 0.7827797202797203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Option 1: Clip the data to ensure non-negative values (since BERT embeddings can be negative)\n",
        "X_train_clipped = X_train.apply(lambda x: np.clip(x, 0, None))\n",
        "X_test_clipped = X_test.apply(lambda x: np.clip(x, 0, None))\n",
        "\n",
        "# Train the Naive Bayes classifier using clipped data\n",
        "nb_classifier.fit(X_train_clipped.to_list(), y_train)\n",
        "\n",
        "# Make predictions on the test set using clipped data\n",
        "y_pred_clipped = nb_classifier.predict(X_test_clipped.to_list())\n",
        "\n",
        "# Evaluate the model with clipped data\n",
        "accuracy_clipped = accuracy_score(y_test, y_pred_clipped)\n",
        "print(f\"Accuracy with Clipped Data: {accuracy_clipped}\")\n",
        "\n",
        "# Generate classification report for clipped data\n",
        "nb_report_clipped = classification_report(y_test, y_pred_clipped, target_names=['Class 0', 'Class 1'])\n",
        "print(\"Naive Bayes Classification Report with Clipped Data:\\n\", nb_report_clipped)\n",
        "\n",
        "# Option 2: Scale the data to be positive (using MinMaxScaler)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(np.vstack(X_train.values))\n",
        "X_test_scaled = scaler.transform(np.vstack(X_test.values))\n",
        "\n",
        "# Train the Naive Bayes classifier using scaled data\n",
        "nb_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set using scaled data\n",
        "y_pred_scaled = nb_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model with scaled data\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy with Scaled Data: {accuracy_scaled}\")\n",
        "\n",
        "# Generate classification report for scaled data\n",
        "nb_report_scaled = classification_report(y_test, y_pred_scaled, target_names=['Class 0', 'Class 1'])\n",
        "print(\"Naive Bayes Classification Report with Scaled Data:\\n\", nb_report_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZHJ-HwXEASD",
        "outputId": "5a9999ab-029a-4060-e85d-696c73106868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Clipped Data: 0.7827797202797203\n",
            "Naive Bayes Classification Report with Clipped Data:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.93      0.80      0.86      1931\n",
            "     Class 1       0.39      0.69      0.50       357\n",
            "\n",
            "    accuracy                           0.78      2288\n",
            "   macro avg       0.66      0.74      0.68      2288\n",
            "weighted avg       0.85      0.78      0.80      2288\n",
            "\n",
            "Accuracy with Scaled Data: 0.861451048951049\n",
            "Naive Bayes Classification Report with Scaled Data:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.87      0.98      0.92      1931\n",
            "     Class 1       0.65      0.24      0.35       357\n",
            "\n",
            "    accuracy                           0.86      2288\n",
            "   macro avg       0.76      0.61      0.64      2288\n",
            "weighted avg       0.84      0.86      0.83      2288\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression** deals with discrete classes using the\n",
        "natural logarithm. It transforms its output using the logistic\n",
        "sigmoid function to return a probability value which can then\n",
        "be mapped to two or more discrete classes. Authors used NLP\n",
        "techniques to represent requirement sentences in suitable\n",
        "form."
      ],
      "metadata": {
        "id": "p5gLVHf32wHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "logreg_classifier = LogisticRegression(max_iter=1000)  # Increased max_iter to ensure convergence\n",
        "\n",
        "# Train the Logistic Regression classifier\n",
        "logreg_classifier.fit(X_train.to_list(), y_train)  # Convert X_train to a list of lists\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logreg_classifier.predict(X_test.to_list())  # Convert X_test to a list of lists\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of Logistic Regression classifier: {accuracy}\")\n",
        "\n",
        "# Generate and print a classification report with precision, recall, and F1 score\n",
        "logreg_report = classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1'])  # Adjust class names if needed\n",
        "print(\"Logistic Regression Classification Report:\\n\", logreg_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFRT3vs6w-Bh",
        "outputId": "307f2f65-ae4f-4e51-d5cf-81a9091792cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Logistic Regression classifier: 0.9117132867132867\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.94      0.96      0.95      1931\n",
            "     Class 1       0.76      0.64      0.69       357\n",
            "\n",
            "    accuracy                           0.91      2288\n",
            "   macro avg       0.85      0.80      0.82      2288\n",
            "weighted avg       0.91      0.91      0.91      2288\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TensorFlow** is a software library for machine learning and artificial intelligence. It can be used for range of tasks but mainly for training and inference of neural networks. It is one of the most popular deep learning frameworks, alongside others such as PyTorch and PaddlePaddle. It is free and open-source software released under the Apache License 2.0."
      ],
      "metadata": {
        "id": "CUGH7a0v8-hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4MBUeNojIwC",
        "outputId": "496c0b72-1599-4e52-e6ab-66db01c01bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN stands for Convolutional Neural Network** which is commonly applied for analyzing image classification. CNN takes an input image as 3 dimensional array based on the image resolution . The height and the width of the image represented 2 dimensions of the array while the third dimension is the color of the pixel (RGB).\n",
        "\n"
      ],
      "metadata": {
        "id": "P_unh9DE36IM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the CNN model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(X_train.iloc[0].shape[0], 1)),  # Input shape adjusted for 1D CNN\n",
        "        layers.Conv1D(32, 3, activation=\"relu\"),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Conv1D(64, 3, activation=\"relu\"),\n",
        "        layers.MaxPooling1D(pool_size=2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10, activation=\"relu\"),  # Adjust the number of units as needed\n",
        "        layers.Dense(1, activation=\"sigmoid\"),  # Output layer for binary classification\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Reshape the input data for the CNN\n",
        "X_train_reshaped = np.array(X_train.to_list()).reshape(-1, X_train.iloc[0].shape[0], 1)\n",
        "X_test_reshaped = np.array(X_test.to_list()).reshape(-1, X_train.iloc[0].shape[0], 1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_reshaped, y_train, epochs=30, batch_size=32, validation_split=0.1) # Adjust epochs and batch_size\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"CNN Test Loss: {loss:.4f}\")\n",
        "print(f\"CNN Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLQPViqHxJHB",
        "outputId": "6c4af282-15bf-43f1-e978-c23a40ee3f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.8272 - loss: 0.4309 - val_accuracy: 0.8504 - val_loss: 0.3258\n",
            "Epoch 2/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8601 - loss: 0.3161 - val_accuracy: 0.8810 - val_loss: 0.2969\n",
            "Epoch 3/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8846 - loss: 0.2832 - val_accuracy: 0.8799 - val_loss: 0.2675\n",
            "Epoch 4/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8916 - loss: 0.2711 - val_accuracy: 0.8734 - val_loss: 0.2590\n",
            "Epoch 5/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8984 - loss: 0.2506 - val_accuracy: 0.8886 - val_loss: 0.2487\n",
            "Epoch 6/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9053 - loss: 0.2397 - val_accuracy: 0.8843 - val_loss: 0.2419\n",
            "Epoch 7/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9056 - loss: 0.2340 - val_accuracy: 0.8865 - val_loss: 0.2690\n",
            "Epoch 8/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9126 - loss: 0.2121 - val_accuracy: 0.8974 - val_loss: 0.2425\n",
            "Epoch 9/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.2030 - val_accuracy: 0.8854 - val_loss: 0.2760\n",
            "Epoch 10/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9209 - loss: 0.1920 - val_accuracy: 0.9007 - val_loss: 0.2249\n",
            "Epoch 11/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9351 - loss: 0.1806 - val_accuracy: 0.8832 - val_loss: 0.2639\n",
            "Epoch 12/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9307 - loss: 0.1689 - val_accuracy: 0.9007 - val_loss: 0.2200\n",
            "Epoch 13/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.1564 - val_accuracy: 0.8985 - val_loss: 0.2252\n",
            "Epoch 14/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1594 - val_accuracy: 0.9138 - val_loss: 0.2188\n",
            "Epoch 15/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.1418 - val_accuracy: 0.9017 - val_loss: 0.2229\n",
            "Epoch 16/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.1327 - val_accuracy: 0.9072 - val_loss: 0.2509\n",
            "Epoch 17/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1178 - val_accuracy: 0.9039 - val_loss: 0.2300\n",
            "Epoch 18/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9600 - loss: 0.1142 - val_accuracy: 0.9028 - val_loss: 0.2525\n",
            "Epoch 19/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9685 - loss: 0.0989 - val_accuracy: 0.8996 - val_loss: 0.2818\n",
            "Epoch 20/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9716 - loss: 0.0943 - val_accuracy: 0.9039 - val_loss: 0.2407\n",
            "Epoch 21/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9713 - loss: 0.0878 - val_accuracy: 0.8963 - val_loss: 0.2575\n",
            "Epoch 22/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.0845 - val_accuracy: 0.8941 - val_loss: 0.2555\n",
            "Epoch 23/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 0.0730 - val_accuracy: 0.9138 - val_loss: 0.2402\n",
            "Epoch 24/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.1359 - val_accuracy: 0.9148 - val_loss: 0.2548\n",
            "Epoch 25/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.1042 - val_accuracy: 0.9214 - val_loss: 0.2351\n",
            "Epoch 26/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.0953 - val_accuracy: 0.9039 - val_loss: 0.2506\n",
            "Epoch 27/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.0855 - val_accuracy: 0.9116 - val_loss: 0.2451\n",
            "Epoch 28/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9763 - loss: 0.0790 - val_accuracy: 0.9061 - val_loss: 0.2468\n",
            "Epoch 29/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0761 - val_accuracy: 0.9159 - val_loss: 0.2860\n",
            "Epoch 30/30\n",
            "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.0691 - val_accuracy: 0.9116 - val_loss: 0.2754\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9099 - loss: 0.3037\n",
            "CNN Test Loss: 0.3020\n",
            "CNN Test Accuracy: 0.9122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Reshape BERT embeddings to (samples, sequence_length, features)\n",
        "X_train_reshaped = np.array(X_train.to_list()).reshape(-1, X_train.iloc[0].shape[0], 1)\n",
        "X_test_reshaped = np.array(X_test.to_list()).reshape(-1, X_train.iloc[0].shape[0], 1)\n",
        "\n",
        "# Convert reshaped data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_reshaped, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_reshaped, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Define CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, sequence_length):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "\n",
        "        # Dummy forward pass to calculate the output size after pooling\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 1, sequence_length)\n",
        "            conv_out = self.pool(self.conv1(dummy_input))\n",
        "            self.flatten_size = conv_out.numel()\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flatten_size, 2)  # Adjust for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # Permute to (batch, channels, sequence_length)\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.reshape(x.size(0), -1)  # Flatten for fully connected layer\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "cnn_model = CNNModel(sequence_length=X_train_reshaped.shape[1])\n",
        "cnn_model.to(device) # Instantiate CNN model\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "def train_cnn(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "train_cnn(cnn_model, train_loader, criterion, optimizer)\n",
        "\n",
        "# Evaluate CNN\n",
        "def evaluate_cnn(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return classification_report(all_labels, all_preds)\n",
        "\n",
        "cnn_report = evaluate_cnn(cnn_model, test_loader)\n",
        "print(\"CNN Model Classification Report:\\n\", cnn_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7hny-s65MZ0",
        "outputId": "6b56e83c-c233-46ed-cec4-41be151eb76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Model Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.58      0.73      1931\n",
            "           1       0.30      0.96      0.45       357\n",
            "\n",
            "    accuracy                           0.64      2288\n",
            "   macro avg       0.64      0.77      0.59      2288\n",
            "weighted avg       0.88      0.64      0.69      2288\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fusion Model\n",
        "A fusion model in machine learning refers to a model that combines multiple different sources, techniques, or models to improve the overall performance, robustness, and accuracy of the predictions. The idea of this approach is to combine the four NLP techniques in on fused model. The objective of this\n",
        "model is to exploit all of the good features from all NLP methods in one combined module. In this model each NLP technique has distinctive features."
      ],
      "metadata": {
        "id": "q2pmkc92FNJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you already have your text data in `df['sentence']` and labels in `df['label']`\n",
        "dataset_path = 'Pure_Annotate_Dataset.csv'\n",
        "try:\n",
        "    df = pd.read_csv(dataset_path, encoding='ISO-8859-1')\n",
        "except UnicodeDecodeError:\n",
        "    # If ISO-8859-1 doesn't work, you can try 'latin1' or 'utf-16'\n",
        "    df = pd.read_csv(dataset_path, encoding='latin1')\n",
        "\n",
        "# Prepare data\n",
        "X = df['sentence']\n",
        "y = df['NFR_boolean']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# 2. Word2Vec\n",
        "# Train Word2Vec model on the training data\n",
        "sentences_train = [sentence.split() for sentence in X_train]\n",
        "sentences_test = [sentence.split() for sentence in X_test]\n",
        "word2vec_model = Word2Vec(sentences_train, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Create Word2Vec features for training and testing sets\n",
        "def get_word2vec_features(sentences, model):\n",
        "    features = []\n",
        "    for sentence in sentences:\n",
        "        vec = np.zeros(100)  # Initialize with zeros\n",
        "        count = 0\n",
        "        for word in sentence:\n",
        "            if word in model.wv:\n",
        "                vec += model.wv[word]\n",
        "                count += 1\n",
        "        if count > 0:\n",
        "            vec /= count\n",
        "        features.append(vec)\n",
        "    return np.array(features)\n",
        "\n",
        "X_train_word2vec = get_word2vec_features(sentences_train, word2vec_model)\n",
        "X_test_word2vec = get_word2vec_features(sentences_test, word2vec_model)\n",
        "\n",
        "# 3. BERT Embeddings\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Convert sentences to BERT embeddings\n",
        "def get_bert_embeddings(sentences, tokenizer, model):\n",
        "    inputs = tokenizer(list(sentences), padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()  # Take the mean of the last layer hidden states\n",
        "\n",
        "X_train_bert = get_bert_embeddings(X_train, tokenizer, bert_model)\n",
        "X_test_bert = get_bert_embeddings(X_test, tokenizer, bert_model)\n",
        "\n",
        "# 4. Bag of Words (BoW)\n",
        "bow_vectorizer = CountVectorizer(max_features=5000)\n",
        "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
        "X_test_bow = bow_vectorizer.transform(X_test)\n",
        "\n",
        "# 5. Combine all features into one fusion model\n",
        "# Concatenate all features (TF-IDF + Word2Vec + BERT + BoW)\n",
        "X_train_combined = np.concatenate([X_train_tfidf.toarray(), X_train_word2vec, X_train_bert, X_train_bow.toarray()], axis=1)\n",
        "X_test_combined = np.concatenate([X_test_tfidf.toarray(), X_test_word2vec, X_test_bert, X_test_bow.toarray()], axis=1)\n",
        "\n",
        "# Train a classifier on the fused features\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train_combined, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test_combined)\n",
        "\n",
        "# Evaluate the model using classification metrics\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0JA_81PGtLw",
        "outputId": "785205f9-ba6f-4e80-c655-424fc0e452d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Implementation of Fusion model, Now we have to calculate the Accuracy of the Fusion model with respect to Precison, Recall and F1 Score."
      ],
      "metadata": {
        "id": "fhGIMH7bWLM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 1. Train individual models: SVM, Logistic Regression, Naive Bayes\n",
        "\n",
        "# Train SVM model\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)\n",
        "svm_classifier.fit(X_train.to_list(), y_train)\n",
        "y_pred_svm = svm_classifier.predict(X_test.to_list())\n",
        "\n",
        "# Train Logistic Regression model\n",
        "logreg_classifier = LogisticRegression(max_iter=1000)\n",
        "logreg_classifier.fit(X_train.to_list(), y_train)\n",
        "y_pred_logreg = logreg_classifier.predict(X_test.to_list())\n",
        "\n",
        "# Train Naive Bayes model\n",
        "nb_classifier = MultinomialNB()\n",
        "X_train_clipped = X_train.apply(lambda x: np.clip(x, 0, None))\n",
        "nb_classifier.fit(X_train_clipped.to_list(), y_train)\n",
        "X_test_clipped = X_test.apply(lambda x: np.clip(x, 0, None))\n",
        "y_pred_nb = nb_classifier.predict(X_test_clipped.to_list())\n",
        "\n",
        "# 2. Train CNN model (assuming you already have the CNN model and the training function)\n",
        "\n",
        "# Assuming CNN training and evaluation functions are implemented\n",
        "# Use the previously defined function to get CNN predictions\n",
        "def get_cnn_predictions(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "    return np.array(all_preds)\n",
        "\n",
        "# Get CNN predictions (assuming test_loader is already prepared)\n",
        "y_pred_cnn = get_cnn_predictions(cnn_model, test_loader)\n",
        "\n",
        "# 3. Fuse the predictions using majority voting\n",
        "# Stack the predictions of the four models\n",
        "predictions_stack = np.stack([y_pred_svm, y_pred_logreg, y_pred_nb, y_pred_cnn], axis=1)\n",
        "\n",
        "# Majority voting (mode of the predictions)\n",
        "from scipy.stats import mode\n",
        "y_pred_fusion, _ = mode(predictions_stack, axis=1)\n",
        "\n",
        "# 4. Generate the classification report for the Fusion Model\n",
        "report_fusion = classification_report(y_test, y_pred_fusion)\n",
        "print(\"Fusion Model Classification Report:\\n\", report_fusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BBPL8QtoWdsP",
        "outputId": "cf0be60c-d8c5-40dd-e0d1-472a2cb4bc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-241ea0343990>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Evaluate the model using classification metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class 0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Class 1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZbaLejtLXCRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "The system evaluation is achieved by randomly splitting dataset into two subsets; train and test. The training set is used for training ML classifiers, while test set is used only for testing the performance of the classifiers.\n",
        "It is worth saying the test dataset has never been used in training. Training dataset was used to train front-end classifiers. The test set was used for both training and testing the back-end classifier. The test set was divided into two equal non-overlapped subsets. One subset was used to train the backend classifier and the second was used to evaluate it. Then, the two subsets were exchanged and the same experiment is repeated\n",
        "\n",
        "The total number of requirement instances are 1247. The splitting process split 872 instances for training, and 375 instances for testing. In fusion model, the dataset was split as in all experiments 70:30."
      ],
      "metadata": {
        "id": "g4PhRQjdYxD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# Upload your dataset (CSV)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the dataset into pandas dataframe (assuming CSV format)\n",
        "#X_test = pd.read_csv('testData.csv')  # Update with your actual filename\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "JJomNCT6lmj_",
        "outputId": "c053dcd9-f5ec-481b-9104-570c5b7057df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-40657c22-a254-40ae-b409-e4e7f91ef6c9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-40657c22-a254-40ae-b409-e4e7f91ef6c9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving testData.csv to testData (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Assuming your new data is in CSV format (replace 'your_new_dataset.csv' with your actual file)\n",
        "new_df = pd.read_csv('testData.csv')\n",
        "\n",
        "# Preprocessing (tokenization, cleaning, lemmatization)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Tokenization\n",
        "new_df['tokens'] = new_df['requirement_sentence'].apply(word_tokenize)\n",
        "\n",
        "# Clean tokens (remove special characters and convert to lowercase)\n",
        "def clean_tokens(tokens):\n",
        "    cleaned_tokens = [re.sub(r'[^A-Za-z]', '', token).lower() for token in tokens if re.sub(r'[^A-Za-z]', '', token)]\n",
        "    return cleaned_tokens\n",
        "\n",
        "new_df['cleaned_tokens'] = new_df['tokens'].apply(clean_tokens)\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "new_df['lemmatized_tokens'] = new_df['cleaned_tokens'].apply(lemmatize_tokens)\n",
        "\n",
        "# Extract BERT Embeddings (ensure the model and tokenizer are loaded)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to get BERT embeddings for each sentence\n",
        "def get_bert_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "new_df['bert_embeddings'] = new_df['lemmatized_tokens'].apply(lambda x: get_bert_embeddings(' '.join(x)))\n",
        "\n",
        "# Flatten the BERT embeddings for the model input\n",
        "X_new = new_df['bert_embeddings'].apply(lambda x: x.flatten())\n",
        "\n",
        "# Assuming 'label' is your target column\n",
        "# Encode labels if necessary\n",
        "#label_encoder = LabelEncoder()\n",
        "#y_new = label_encoder.fit_transform(new_df['label'])  # If the label is not already numeric\n",
        "\n",
        "# Reshape the input data for CNN\n",
        "X_new_reshaped = np.array(X_new.to_list()).reshape(-1, X_new.iloc[0].shape[0], 1)\n",
        "\n",
        "# Load your trained CNN model (assuming it's saved previously)\n",
        "# If you haven't saved the model, use the code below to train it first\n",
        "# cnn_model = keras.models.load_model('path_to_your_trained_model')\n",
        "\n",
        "# Use the trained model to make predictions\n",
        "predictions = cnn_model.predict(X_new_reshaped)\n",
        "\n",
        "# If the model output is a binary classification, you can use the following\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Convert predictions back to label names if needed\n",
        "predicted_label_names = label_encoder.inverse_transform(predicted_labels.flatten())\n",
        "\n",
        "# Add the predictions to your dataframe\n",
        "new_df['predicted_labels'] = predicted_label_names\n",
        "\n",
        "# Display the results\n",
        "print(new_df[['sentence', 'predicted_labels']])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "Pgo5MN3ImIpd",
        "outputId": "01feb973-c93d-4ecc-8e54-67a155cd3b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'BertModel' object has no attribute 'predict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6834230b3a04>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Use the trained model to make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# If the model output is a binary classification, you can use the following\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BertModel' object has no attribute 'predict'"
          ]
        }
      ]
    }
  ]
}